{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNPSSU504fOa/+5rW5lCSX0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anshika-Choudhary/Prediction-of-Sugarcane-Yield-Using-ML-Models/blob/main/Data_Cleaning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA** **SOURCES**"
      ],
      "metadata": {
        "id": "fIap3V-VjaIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The MODIS(Moderate-Resolution Imaging Spectroradiometer)  provides medium-resolution data\n",
        " globally and provides around forty-four principal geo\n",
        "physical products.\n",
        "\n",
        "The following products were used-  \n",
        "\n",
        "  MOD 13: Normalized Difference Vegetation Index (NDVI) and Enhanced Vegetation Index (EVI);\n",
        "\n",
        "MOD15: Leaf Area Index (LAI) and Fraction of Photosynthetically\n",
        " Active Radiation (FPAR);\n",
        "\n",
        "MOD16 : Evapotranspiration (ET) ;\n",
        "\n",
        "MOD17 : Gross Primary Product (GPP) .\n",
        "\n",
        "**Vegetation and Productivity Indices **\n",
        "\n",
        "1.NDVI (Normalized Difference Vegetation Index)\n",
        "\n",
        "Indicates vegetation greenness and health using red and near-infrared reflectance.\n",
        "\n",
        "Ranges from -1 to +1, where higher values show dense and healthy vegetation.\n",
        "\n",
        "Commonly used in crop monitoring and drought assessment.\n",
        "\n",
        "2.EVI (Enhanced Vegetation Index)\n",
        "\n",
        "An improvement over NDVI, especially in dense forests or high humidity areas.\n",
        "\n",
        "Uses blue reflectance to correct for atmospheric effects and provides more accurate vegetation estimates.\n",
        "\n",
        "3.LAI (Leaf Area Index)\n",
        "\n",
        "Represents the total leaf surface area per unit ground area.\n",
        "\n",
        "Reflects canopy density and is critical for understanding photosynthesis, water use, and plant growth.\n",
        "\n",
        "4.GPP (Gross Primary Productivity)\n",
        "\n",
        "Measures the total carbon fixed by plants through photosynthesis.\n",
        "\n",
        "Indicates the overall productivity of vegetation and is used in carbon cycle modeling.\n",
        "\n",
        "5.ET (Evapotranspiration)\n",
        "\n",
        "Combines soil evaporation and plant transpiration to estimate total water loss.\n",
        "\n",
        "Useful in understanding crop water requirements and irrigation management.\n",
        "\n",
        "6.FPAR (Fraction of Photosynthetically Active Radiation)\n",
        "\n",
        "Measures the fraction of sunlight absorbed by plants for photosynthesis.\n",
        "\n",
        "Directly related to GPP and indicates how efficiently plants use sunlight for growth.\n",
        "\n",
        "The products for the study area were extracted using the\n",
        " Application for Extracting and Exploring Analysis Ready\n",
        " Samples (AppEEARS) (AppEEARS Team, 2020).\n",
        " AppEEARS enables users to access efficiently subset geospatial\n",
        " datasets using spatial, temporal, and layer parameters.\n",
        "\n",
        "\n",
        "Yield data of sugarcane for 15 districts of West Uttar Pradesh was obtained from ICRISAT(International Crops Research Institute for the Semi-Arid Tropics)"
      ],
      "metadata": {
        "id": "XroHqKR3DhzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "All the 6 vegetative indices were collected by raising request on AppEEARS for 15 Districts of west Uttar Pradesh viz (muzaffarnagar,\n",
        "bulandshahr,\n",
        "meerut,\n",
        "saharanpur,\n",
        "aligarh,\n",
        "mathura,\n",
        "agra,\n",
        "mainpuri,\n",
        "moradabad,\n",
        "rampur,\n",
        "bijnor,\n",
        "bareilly,\n",
        "etah,\n",
        "shahjahanpur,\n",
        "pilibhit,\n",
        "badaun,\n",
        "Kasganj.)\n",
        "\n",
        "\n",
        "These indices are crucial for monitoring vegetation health, estimating crop yield, analyzing water use, and modeling ecosystem productivity.\n",
        " The indices had different temporal and\n",
        " spatial resolutions.\n",
        "\n",
        "Data obtained in form of csv files which   consists of various statistical parameters ,column filtering was done as to keep only the mean value of the indices for the given district for each month of year .\n"
      ],
      "metadata": {
        "id": "wS3utCeeixo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CODE**\n",
        "\n",
        "\n",
        "The following code was used to execute the task,it was done for all 15 districts by simply replacing input data and changing the names where required."
      ],
      "metadata": {
        "id": "udTcqog4mWMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "COLUMN FILTERING\n"
      ],
      "metadata": {
        "id": "oudajYDDo3RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/MOD13Q1-061-Statistics_(2)[1].csv')\n",
        "\n",
        "#  Drop  columns\n",
        "columns_to_keep = ['Dataset','Date', 'Mean']\n",
        "df = df[columns_to_keep]\n",
        "\n",
        "# Create separate columns for NDVI Mean and EVI Mean\n",
        "\n",
        "df['EVI Mean'] = df.apply(lambda row: row['Mean'] if 'EVI' in row['Dataset'] else None, axis=1)\n",
        "df['NDVI Mean'] = df.apply(lambda row: row['Mean'] if 'NDVI' in row['Dataset'] else None, axis=1)\n",
        "\n",
        "# Drop the original Mean column\n",
        "df.drop(columns=['Mean'], inplace=True)\n",
        "\n",
        "# Convert Date column to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Extract year and month for grouping\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "\n",
        "# Group by Year and Month and calculate monthly mean for both NDVI and EVI\n",
        "monthly_avg = df.groupby(['Year', 'Month']).agg({\n",
        "    'NDVI Mean': 'mean',\n",
        "    'EVI Mean': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        " # Add a new column for District\n",
        "monthly_avg['District'] = 'Muzaffarnagar'\n",
        "\n",
        "#  Save monthly means to new CSV\n",
        "monthly_avg.to_csv(\"muzaffarnagar_monthly_ndvi_evi_means.csv\", index=False)"
      ],
      "metadata": {
        "id": "KPtdS3oy-P6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/MOD15A2H-061-Statistics_(1)[1].csv')\n",
        "\n",
        "#  Drop  columns\n",
        "columns_to_keep = ['Dataset','Date', 'Mean']\n",
        "df = df[columns_to_keep]\n",
        "# Create separate columns for Fpar Mean and Lai Mean\n",
        "\n",
        "df['Fpar Mean'] = df.apply(lambda row: row['Mean'] if 'Fpar' in row['Dataset'] else None, axis=1)\n",
        "df['Lai Mean'] = df.apply(lambda row: row['Mean'] if 'Lai' in row['Dataset'] else None, axis=1)\n",
        "\n",
        "# Drop the original Mean column\n",
        "df.drop(columns=['Mean'], inplace=True)\n",
        "\n",
        "# Convert Date column to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Extract year and month for grouping\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "\n",
        "# Group by Year and Month and calculate monthly mean for both Fpar and Lai\n",
        "monthly_avg = df.groupby(['Year', 'Month']).agg({\n",
        "    'Fpar Mean': 'mean',\n",
        "    'Lai Mean': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        " # Add a new column for District\n",
        "monthly_avg['District'] = 'Muzaffarnagar'\n",
        "\n",
        "#  Save monthly means to new CSV\n",
        "monthly_avg.to_csv(\"muzaffarnagar_monthly_fpar_lai_means.csv\", index=False)"
      ],
      "metadata": {
        "id": "dBFjShkNEIze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/MOD16A2GF-061-Statistics_(1)[1].csv')\n",
        "\n",
        "#  Drop  columns\n",
        "columns_to_keep = ['Dataset','Date', 'Mean']\n",
        "df = df[columns_to_keep]\n",
        "\n",
        "# Create separate columns for ET Mean\n",
        "\n",
        "df['ET Mean'] = df.apply(lambda row: row['Mean'] if 'ET' in row['Dataset'] else None, axis=1)\n",
        "\n",
        "# Drop the original Mean column\n",
        "df.drop(columns=['Mean'], inplace=True)\n",
        "\n",
        "# Convert Date column to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Extract year and month for grouping\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "\n",
        "# Group by Year and Month and calculate monthly mean for ET\n",
        "monthly_avg = df.groupby(['Year', 'Month']).agg({\n",
        "    'ET Mean': 'mean',\n",
        "\n",
        "}).reset_index()\n",
        "\n",
        " # Add a new column for District\n",
        "monthly_avg['District'] = 'Muzaffarnagar'\n",
        "\n",
        "#  Save monthly means to new CSV\n",
        "monthly_avg.to_csv(\"muzaffarnagar_monthly_et_means.csv\", index=False)"
      ],
      "metadata": {
        "id": "8CFd-3OMEJBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/MOD17A2HGF-061-Statistics_(1)[1].csv')\n",
        "\n",
        "#  Drop  columns\n",
        "columns_to_keep = ['Dataset','Date', 'Mean']\n",
        "df = df[columns_to_keep]\n",
        "\n",
        "# Create separate columns for Gpp Mean\n",
        "\n",
        "df['Gpp Mean'] = df.apply(lambda row: row['Mean'] if 'Gpp' in row['Dataset'] else None, axis=1)\n",
        "\n",
        "# Drop the original Mean column\n",
        "df.drop(columns=['Mean'], inplace=True)\n",
        "\n",
        "# Convert Date column to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Extract year and month for grouping\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "\n",
        "# Group by Year and Month and calculate monthly mean for Gpp\n",
        "monthly_avg = df.groupby(['Year', 'Month']).agg({\n",
        "    'Gpp Mean': 'mean',\n",
        "\n",
        "}).reset_index()\n",
        "\n",
        " # Add a new column for District\n",
        "monthly_avg['District'] = 'Muzaffarnagar'\n",
        "\n",
        "# Save monthly means to new CSV\n",
        "monthly_avg.to_csv(\"muzaffarnagar_monthly_gpp_means.csv\", index=False)"
      ],
      "metadata": {
        "id": "JaWYIVfSEJn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MERGE ALL THE INDICIES DATA IN ONE CSV FILE"
      ],
      "metadata": {
        "id": "nLYqsihq5dXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "files = ['/content/muzaffarnagar_monthly_et_means.csv','/content/muzaffarnagar_monthly_fpar_lai_means.csv','/content/muzaffarnagar_monthly_gpp_means.csv','/content/muzaffarnagar_monthly_ndvi_evi_means.csv']\n",
        "\n",
        "# Read all files into a list of DataFrames\n",
        "dfs = [pd.read_csv(file) for file in files]\n",
        "\n",
        "# Merge all DataFrames on common column\n",
        "from functools import reduce\n",
        "merged_df = reduce(lambda left, right: pd.merge(left, right, on=[\"Year\",\"Month\",\"District\"], how='inner'), dfs)\n",
        "\n",
        "# Save the merged DataFrame\n",
        "merged_df.to_csv(\"muzaffarnagar_final.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "VuMkyi4CI8C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAKING  EACH MONTHLY INDEX AS AN VARIABLE(seperate column)"
      ],
      "metadata": {
        "id": "v9obfFWF5KCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df2 = pd.read_csv('/content/Shahjahanpur_final.csv')\n",
        "\n",
        "#convert numeric months to names\n",
        "month_map = {\n",
        "    1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr',\n",
        "    5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug',\n",
        "    9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'\n",
        "}\n",
        "df2['Month'] = df2['Month'].map(month_map)\n",
        "id_vars_list = ['Year', 'Month']\n",
        "\n",
        "#  Reshape from wide to long format\n",
        "df2_long = df2.melt(id_vars=['Year', 'Month'],\n",
        "                  var_name='Index',\n",
        "                  value_name='Value')\n",
        "\n",
        "#  Create new column names like Jan_NDVI\n",
        "df2_long['Month_Index'] = df2_long['Month'] + '_' + df2_long['Index'].str.replace('_mean', '')\n",
        "\n",
        "#  Pivot to get the desired format\n",
        "df2_wide = df2_long.pivot(index='Year', columns='Month_Index', values='Value')\n",
        "\n",
        "#  Reset index and sort columns for neatness\n",
        "d2f_wide = df2_wide.reset_index()\n",
        "df2_wide = df2_wide[['Year'] + sorted([col for col in df2_wide.columns if col != 'Year'])]\n",
        "\n",
        "#  Save to CSV\n",
        "df2_wide.to_csv('Shahjahanpurf1.csv', index=False)\n"
      ],
      "metadata": {
        "id": "eSveVecexg_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAKING COMBINED FILE FOR ALL DISTRICT"
      ],
      "metadata": {
        "id": "5Ync7BulW-Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "agra_df = pd.read_csv('/content/Agraf1.csv')\n",
        "aligarh_df = pd.read_csv('/content/Aligarhf1.csv')\n",
        "badaun_df = pd.read_csv('/content/Badaunf1.csv')\n",
        "bareilly_df = pd.read_csv('/content/Bareillyf1.csv')\n",
        "bijnor_df = pd.read_csv('/content/Bijnorf1.csv')\n",
        "bulandshahr_df = pd.read_csv('/content/Bulandshahrf1.csv')\n",
        "etah_df = pd.read_csv('/content/Etahf1.csv')\n",
        "mainpuri_df = pd.read_csv('/content/Mainpurif1.csv')\n",
        "mathura_df = pd.read_csv('/content/Mathuraf1.csv')\n",
        "meerut_df = pd.read_csv('/content/Meerutf1.csv')\n",
        "moradabad_df = pd.read_csv('/content/Moradabadf1.csv')\n",
        "pilibhit_df = pd.read_csv('/content/Pilibhitf1.csv')\n",
        "rampur_df = pd.read_csv('/content/Rampurf1.csv')\n",
        "saharanpur_df = pd.read_csv('/content/Saharanpurf1.csv')\n",
        "shahjahanpur_df = pd.read_csv('/content/Shahjahanpurf1.csv')\n",
        "muzaffarnagar_df = pd.read_csv('/content/muzaffarnagarf1.csv')\n",
        "\n",
        "# Merge based on common keys: Year, Month, District\n",
        "dfs1 = [\n",
        "    agra_df, aligarh_df, badaun_df, bareilly_df, bijnor_df, bulandshahr_df,\n",
        "    etah_df, mainpuri_df, mathura_df, meerut_df, moradabad_df, pilibhit_df,\n",
        "    rampur_df, saharanpur_df, shahjahanpur_df, muzaffarnagar_df\n",
        "]\n",
        "combined_df = pd.concat(dfs1, ignore_index=True)\n",
        "\n",
        "# Save to CSV\n",
        "combined_df.to_csv('all_districts_combined.csv', index=False)\n"
      ],
      "metadata": {
        "id": "tjiDoi__6UMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMBINING YIELD DATA AND INDICES DATA"
      ],
      "metadata": {
        "id": "FrUP3696XOnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "yield_df=pd.read_csv('/content/ICRISAT-District Level Data.csv')\n",
        "index_df=pd.read_csv('/content/all_districts_combined.csv')\n",
        "# Clean district column\n",
        "yield_df['District'] = yield_df['District'].str.strip().str.upper()\n",
        "index_df['District'] = index_df['District'].str.strip().str.upper()\n",
        "dfs2=[yield_df,index_df]\n",
        "from functools import reduce\n",
        "merged_df = reduce(lambda left, right: pd.merge(left, right, on=[\"District\",\"Year\"], how='inner'), dfs2)\n",
        "merged_df.drop(merged_df[merged_df['Year'] == 2000].index, inplace=True)\n",
        "merged_df = df.drop(['SUGARCANE AREA (1000 ha)','SUGARCANE PRODUCTION (1000 tons)','dis code','State Code','State Name','May_District','Jun_District','Jul_District','Aug_District','Sep_District','Oct_District',  'Nov_District','Dec_District','Jan_District','Feb_District','Mar_District'],axis=1)\n",
        "merged_df.to_csv('combined.csv', index=False)"
      ],
      "metadata": {
        "id": "UvEgo3REoM0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iqVgKExYp8RS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}